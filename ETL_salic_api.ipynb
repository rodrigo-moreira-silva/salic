{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     Extração/tratamento/carga de dados da API do SALIC\n",
    "\n",
    "    Fonte: http://api.salic.cultura.gov.br/doc/\n",
    "\n",
    "    Faz a leitura de projetos da lei de incentivo à cultura (antiga Lei Rouanet) entre 2010 e 2022\n",
    "\n",
    "    Desenvolvido na equipe descentralizada de dados (DADOS/CGEBC/DS/SFC) da Controladoria-Geral da União (CGU):\n",
    "\n",
    "    Rodrigo Moreira da Silva e Victorio Takahashi Chu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import glob  \n",
    "import os\n",
    "from tqdm import tqdm \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1 - Extração\n",
    "#### Lendo e gravando dados de PRONAC da API do SALIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data da extração\n",
    "data = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "#Pasta para gravar os dados\n",
    "os.makedirs(f'./dados_api_{data}',exist_ok=True)\n",
    "pasta = (f'dados_api_{data}') + os.sep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_pronac(pronac, data_atual, pasta_dados):\n",
    "\n",
    "    headers = {'accept': 'application/json',}\n",
    "    params = {'format': 'json',}\n",
    "\n",
    "    pronacs_api = ''\n",
    "    data = data_atual\n",
    "    pasta = pasta_dados \n",
    "\n",
    "    try:\n",
    "        r = requests.get(f'http://api.salic.cultura.gov.br/v1/projetos/{pronac}', params=params, headers=headers)\n",
    "        if r.status_code == 200:\n",
    "            status_api = 'Operação bem-sucedida'\n",
    "            with open(f'{pasta}pronac_{pronac}_{data}.json', 'w') as f:\n",
    "                json.dump(r.text, f)\n",
    "        elif r.status_code == 404:\n",
    "            status_api = 'Projeto com PRONAC fornecido não encontrado'\n",
    "        elif r.status_code == 405:\n",
    "            status_api = 'PRONAC inválido' \n",
    "        elif r.status_code == 503:\n",
    "            status_api = 'Erro interno'\n",
    "        else:\n",
    "            status_api = 'Desconhecido'\n",
    "    except:\n",
    "        status_api = 'Erro de conexão'\n",
    "\n",
    "    return status_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chama_leitura_pronacs(lista, data, pasta):\n",
    "    contador = 1\n",
    "    dic = {}\n",
    "    for pronac in tqdm(lista):\n",
    "        dic[pronac] = le_pronac(pronac, data, pasta)\n",
    "        contador += 1\n",
    "        if contador == 100:\n",
    "            contador = 1\n",
    "            time.sleep(5)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anos que serão pesquisados: 2010 a 2022\n",
    "#O PRONAC é formado por 6 dígitos: AASSSS onde AA é o ano do projeto e SSSS é um sequencial que vai de 0001 a 9999\n",
    "#Entre os anos de 2010 e 2015, houve mais de 10.000 projetos. Então o sequencial deve ser mudado para 5 digitos\n",
    "\n",
    "#Projetos de 2010 a 2022\n",
    "pronacs = list(range(100000,230000))\n",
    "#complemento dos pronacs\n",
    "pronacs_2010 = list(range(1010000,1015000))\n",
    "pronacs_2011 = list(range(1110000,1115000))\n",
    "pronacs_2012 = list(range(1210000,1215000))\n",
    "pronacs_2013 = list(range(1310000,1315000))\n",
    "pronacs_2014 = list(range(1410000,1415000))\n",
    "pronacs_2015 = list(range(1510000,1515000))\n",
    "#Junção de todos sos pronacs\n",
    "pronac_todos = pronacs + pronacs_2010 + pronacs_2011 + pronacs_2012 + pronacs_2013 + pronacs_2014 + pronacs_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_status_pronac = {}\n",
    "api_status_pronac = chama_leitura_pronacs(pronac_todos, data, pasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_status_pronac_df = pd.DataFrame(list(api_status_pronac.items()), columns=['pronac','status'])\n",
    "api_status_pronac_df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tentativa_leitura = 0\n",
    "\n",
    "#Separa os Pronac que tiveram erro na leitura e tenta ler novamente (até 8 vezes)\n",
    "while tentativa_leitura < 8:\n",
    "\n",
    "    #Verifica quantos pronacs tiveram erro de leitura\n",
    "    pronac_problema = list(api_status_pronac_df[(api_status_pronac_df['status'] == 'Erro de conexão') | \n",
    "                                                (api_status_pronac_df['status'] == 'Erro interno') | \n",
    "                                                (api_status_pronac_df['status'] == 'Desconhecido')]['pronac'])\n",
    "\n",
    "    #Se for zero problema, sai do loop\n",
    "    if len(pronac_problema) == 0:\n",
    "        break\n",
    "\n",
    "    #Lê os pronacs que tiveram problema na rodada anterior\n",
    "    aux_dic = chama_leitura_pronacs(pronac_problema, data, pasta)\n",
    "    #Transforma o dicionário em dataframe da mesma forma que foi feito para o api_status_pronac_df\n",
    "    aux_df = pd.DataFrame(list(aux_dic.items()), columns=['pronac','status'])\n",
    "    \n",
    "    #Concatena os dataframes api_status_pronac_df e aux_df\n",
    "    #Remove os pronacs duplicados mantendo o status mais recente\n",
    "    api_status_pronac_df = pd.concat([api_status_pronac_df, aux_df])\n",
    "    api_status_pronac_df.drop_duplicates(subset=['pronac'], keep='last', inplace=True)\n",
    "    api_status_pronac_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    tentativa_leitura += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grava em arquivos os pronacs que ainda apresentaram problema de leitura após 5 tentativas\n",
    "if tentativa_leitura >=5:\n",
    "    print(f'Após 5 tentativas de leitura, os pronacs que ainda apresentam problema estão no arquivo pronacs_problema.csv')\n",
    "    pronacs_problema = (api_status_pronac_df[(api_status_pronac_df['status'] == 'Erro de conexão') | \n",
    "                                             (api_status_pronac_df['status'] == 'Erro interno') | \n",
    "                                             (api_status_pronac_df['status'] == 'Desconhecido')]).copy()\n",
    "    \n",
    "    arquivo = f'pronacs_problema_{data}.csv'\n",
    "    pronacs_problema.to_csv(arquivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = f'status_pronac_{data}.csv'\n",
    "api_status_pronac_df.to_csv(arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_status_pronac_df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2 - Tratamento\n",
    "#### Lendo dados gravados do SALIC (json para dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria o dataframe vazio e depois preenche com todos os dados lidos pela API\n",
    "pronacs_df = pd.DataFrame(columns=[ 'etapa', 'providencia', 'area', 'enquadramento', 'objetivos',\n",
    "                                    'ficha_tecnica', 'situacao', 'outras_fontes', 'acessibilidade',\n",
    "                                    'sinopse', 'nome', 'cgccpf', 'mecanismo', '_links', 'segmento',\n",
    "                                    'PRONAC', 'estrategia_execucao', 'valor_aprovado', 'justificativa',\n",
    "                                    'resumo', 'valor_solicitado', 'especificacao_tecnica', '_embedded',\n",
    "                                    'municipio', 'data_termino', 'UF', 'impacto_ambiental',\n",
    "                                    'democratizacao', 'valor_projeto', 'proponente', 'ano_projeto',\n",
    "                                    'data_inicio', 'valor_captado', 'valor_proposta'])\n",
    "\n",
    "#Lê todos os arquivos json que foram extraídos da api do SALIC\n",
    "files = glob.glob(f'{pasta}*.json')\n",
    "for fname in files:\n",
    "    with open(fname, 'r') as f:\n",
    "        data = f.read()\n",
    "        json_data = json.loads(data)\n",
    "        df = pd.read_json(json_data, lines=True)\n",
    "        pronacs_df = pd.concat([pronacs_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronacs_df.rename(columns={'nome':'nome_projeto'}, inplace=True)\n",
    "pronacs_df.rename(columns={'proponente':'nome'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronacs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronacs_df.rename(columns={'nome':'nome_proponente'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronacs_df_simplificado = pronacs_df[['PRONAC','area', 'enquadramento', 'situacao', 'nome_projeto', 'cgccpf', 'nome_proponente','mecanismo', \n",
    "                                      'segmento', 'resumo', 'valor_solicitado', 'municipio', 'UF', 'ano_projeto', 'data_inicio', 'data_termino',\n",
    "                                      'valor_projeto', 'valor_aprovado', 'valor_captado', 'valor_proposta','outras_fontes',]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando dataframe com os documentos de pagamentos\n",
    "df_relacao_pagamentos = pd.DataFrame()\n",
    "\n",
    "for i in range(len(pronacs_df['_embedded'])):\n",
    "    PRONAC =  pronacs_df['PRONAC'][i]\n",
    "    df = pd.DataFrame(pronacs_df['_embedded'][i]['relacao_pagamentos'], \\\n",
    "                      columns = ['id_planilha_aprovacao',\n",
    "                                'justificativa',\n",
    "                                'data_pagamento',\n",
    "                                'nome',\n",
    "                                'cgccpf',\n",
    "                                'data_aprovacao',\n",
    "                                'valor_pagamento',\n",
    "                                'nm_arquivo',\n",
    "                                'id_arquivo',\n",
    "                                'nome_fornecedor',\n",
    "                                'id_comprovante_pagamento',\n",
    "                                'nr_documento_pagamento',\n",
    "                                'tipo_documento'])\n",
    "    df['PRONAC'] = PRONAC\n",
    "    df_relacao_pagamentos = pd.concat([df_relacao_pagamentos,df], ignore_index=True)\n",
    "df_relacao_pagamentos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRONACs que possuem algum tipo de documento de pagamento\n",
    "df_relacao_pagamentos['PRONAC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relacao_pagamentos_agrupado = df_relacao_pagamentos.groupby(['PRONAC', 'cgccpf', 'nome_fornecedor'])['valor_pagamento'].sum().to_frame()\n",
    "df_relacao_pagamentos_agrupado = df_relacao_pagamentos_agrupado.reset_index()\n",
    "df_relacao_pagamentos_agrupado.rename(columns={'nome_fornecedor':'nome'}, inplace=True)\n",
    "df_relacao_pagamentos_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relacao_pagamentos_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe com informações de captações \n",
    "df_captacao = pd.DataFrame()\n",
    "for i in range(len(pronacs_df['_embedded'])):\n",
    "    df = pd.DataFrame(pronacs_df['_embedded'][i]['captacoes'], \\\n",
    "                      columns = ['PRONAC','valor','data_recibo','nome_projeto','cgccpf','nome_doador'])\n",
    "    df_captacao = pd.concat([df_captacao,df], ignore_index=True)\n",
    "df_captacao\n",
    "df_captacao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRONACs que tiveram captação de recursos\n",
    "df_captacao['PRONAC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_captacao_agrupado = df_captacao.groupby(['PRONAC', 'cgccpf', 'nome_doador'])['valor'].sum().to_frame()\n",
    "df_captacao_agrupado = df_captacao_agrupado.reset_index()\n",
    "df_captacao_agrupado.rename(columns={'nome_doador':'nome'}, inplace=True)\n",
    "df_captacao_agrupado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3 - Carga\n",
    "#### Gravando dados em csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronacs_df_simplificado.to_csv('SALIC.csv', index=False, encoding='utf-8')\n",
    "df_relacao_pagamentos.to_csv('SALIC_rel_pagamentos.csv', index=False, encoding='utf-8')\n",
    "df_captacao.to_csv('SALIC_captacao.csv',  index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "12eaf5baf6c45a7c3cf2d29ee969f54aa4875647e2f824e61ad7f4855accc276"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
